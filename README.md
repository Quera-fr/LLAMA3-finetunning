# ğŸ“˜ README - Fine-tuning d'un modÃ¨le LLaMA 3 avec LoRA  

## ğŸ“Œ Description  
Ce projet permet d'affiner (`fine-tuner`) un modÃ¨le **LLaMA 3.2-1B-Instruct** en utilisant **LoRA** (Low-Rank Adaptation). L'entraÃ®nement est rÃ©alisÃ© sur un dataset de conversations, reprÃ©sentant des interactions avec **Quera**, une agence spÃ©cialisÃ©e en Web et Data.  

L'objectif est d'entraÃ®ner un modÃ¨le capable de rÃ©pondre de maniÃ¨re pertinente aux utilisateurs en utilisant le contexte de l'agence.  

---

## ğŸ“‚ Structure du projet  

```bash
ğŸ“¦ projet-finetune-llama3
â”œâ”€â”€ ğŸ“‚ data
â”‚   â”œâ”€â”€ dataset.jsonl        # Dataset des conversations pour l'entraÃ®nement
â”œâ”€â”€ fintetune.py             # Script principal d'entraÃ®nement du modÃ¨le
â”œâ”€â”€ train.sh                 # Script pour la conversion et le dÃ©ploiement du modÃ¨le
â”œâ”€â”€ requirements.txt         # Liste des dÃ©pendances Python
â””â”€â”€ README.md                # Documentation du projet
```

---

## ğŸ“œ DonnÃ©es d'entraÃ®nement (`data/dataset.jsonl`)  

Le dataset est un fichier **JSONL** contenant des dialogues entre un utilisateur et l'assistant **Quera**. Voici un exemple :  

```json
{
  "messages": [
    {"role": "system", "content": "Vous Ãªtes Quera, une agence spÃ©cialisÃ©e en Web et Data, situÃ©e Ã  Paris."},
    {"role": "user", "content": "Quelles sont vos expertises ?"},
    {"role": "assistant", "content": "Nous sommes experts en crÃ©ation de sites WordPress, SEO, Data Science, IA et dÃ©veloppement d'APIs."}
  ]
}
```

---

## ğŸš€ Installation et Environnement  

### 1ï¸âƒ£ Cloner le projet  
```bash
git clone https://github.com/votre-repo/projet-finetune-llama3.git
cd projet-finetune-llama3
git clone https://github.com/ggerganov/llama.cpp.git
```

### 2ï¸âƒ£ Installer les dÃ©pendances  
CrÃ©er un environnement virtuel (recommandÃ©) et installer les bibliothÃ¨ques nÃ©cessaires :  
```bash
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
venv\Scripts\activate     # Sur Windows

pip install -r requirements.txt
```

---

## ğŸ”§ EntraÃ®nement du modÃ¨le (`fintetune.py`)  

Le script **`fintetune.py`** effectue les Ã©tapes suivantes :  
âœ… **Chargement du dataset** (fichier JSONL)  
âœ… **PrÃ©traitement des donnÃ©es** (conversion des conversations en texte formatÃ©)  
âœ… **Tokenization avec un modÃ¨le LLaMA 3**  
âœ… **Fine-tuning avec LoRA**  
âœ… **Sauvegarde du modÃ¨le ajustÃ©**  
âœ… **Fusion des poids LoRA avec le modÃ¨le principal**  

### ğŸ”¥ Lancer l'entraÃ®nement  
```bash
python fintetune.py
```

â³ L'entraÃ®nement peut prendre du temps selon votre machine.  

---

## ğŸ—ï¸ Conversion et DÃ©ploiement (`train.sh`)  

Une fois le modÃ¨le entraÃ®nÃ© et fusionnÃ©, vous pouvez le convertir au format **GGUF** pour l'utiliser avec **Ollama** :  

```bash
bash train.sh
```

Ce script exÃ©cute :  
1. **Conversion du modÃ¨le** en GGUF via `convert_hf_to_gguf.py`  
2. **CrÃ©ation du modÃ¨le Ollama** avec `ollama create`  

---

## ğŸ“Œ DÃ©pendances (`requirements.txt`)  

Le projet utilise les bibliothÃ¨ques suivantes :  

```
torch
transformers
datasets
peft
accelerate
tensorboard
```

Installez-les avec :  
```bash
pip install -r requirements.txt
```

---

## ğŸ“¬ Contact  

ğŸ“§ **Kevin Duranty** - [kevin.duranty@quera.fr](mailto:kevin.duranty@quera.fr)  
ğŸŒ **Agence Quera** - [www.quera.fr](https://www.quera.fr)  

ğŸš€ *La technologie au service du dÃ©veloppement des activitÃ©s humaines.*